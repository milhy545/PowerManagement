#!/usr/bin/env python3

"""
Real MyCoder with AI Generation - Ultra Safe Edition
- SkuteÄnÃ© AI generovÃ¡nÃ­ s TinyLlama
- Thermal monitoring mezi kaÅ¾dÃ½m requestem
- Automatic process limiting
"""

import os
import sys
import time
import json
import asyncio
import aiohttp
import subprocess
import psutil
from dataclasses import dataclass
from typing import Optional, Dict, Any

class ThermalMyCoder:
    def __init__(self):
        self.ollama_url = "http://localhost:11434"
        self.model_name = "tinyllama:1.1b"  # NejlehÄÃ­ model
        self.temp_threshold = 65  # SnÃ­Å¾enÃ½ threshold pro real AI
        self.critical_temp = 70   # JeÅ¡tÄ› vÃ­c konzervativnÃ­
        
        # Limit process to 2 cores
        self.limit_cpu_cores()
        
    def limit_cpu_cores(self):
        """Omez proces na 2 jÃ¡dra"""
        try:
            current_process = psutil.Process()
            current_process.cpu_affinity([0, 1])
            # Set lowest priority
            current_process.nice(19)
            print("âœ… Process: 2 cores, lowest priority")
        except Exception as e:
            print(f"âš ï¸ CPU limiting failed: {e}")
    
    def get_cpu_temperature(self) -> Optional[int]:
        """ZÃ­skej teplotu CPU"""
        try:
            result = subprocess.run(
                ["sensors"], 
                capture_output=True, 
                text=True, 
                timeout=3
            )
            
            for line in result.stdout.split('\n'):
                if "Core 0:" in line:
                    temp_str = line.split('+')[1].split('Â°')[0]
                    return int(float(temp_str))
                    
        except Exception:
            return None
    
    def thermal_safety_check(self) -> bool:
        """Kontrola thermal safety"""
        temp = self.get_cpu_temperature()
        if not temp:
            print("âš ï¸ Cannot read temperature!")
            return False
            
        cpu_usage = psutil.cpu_percent(interval=0.5)
        print(f"ğŸŒ¡ï¸ {temp}Â°C | CPU: {cpu_usage}%", end="")
        
        if temp >= self.critical_temp:
            print(f" ğŸš¨ CRITICAL!")
            self.emergency_thermal_stop()
            return False
            
        if temp >= self.temp_threshold:
            print(f" âš ï¸ HOT! Cooling...")
            time.sleep(15)  # DelÅ¡Ã­ cooldown pro real AI
            return self.thermal_safety_check()
            
        print(" âœ… Safe")
        return True
    
    def emergency_thermal_stop(self):
        """Emergency stop"""
        print("\nğŸš¨ EMERGENCY THERMAL STOP!")
        try:
            # Kill heavy processes
            subprocess.run(["pkill", "-f", "ollama"], check=False)
            subprocess.run(["pkill", "-f", "python.*ollama"], check=False)
            
            # Lower all process priorities
            for proc in psutil.process_iter(['pid']):
                try:
                    proc.nice(19)
                except:
                    pass
                    
            print("âœ… Emergency procedures completed")
        except Exception as e:
            print(f"âŒ Emergency stop failed: {e}")
    
    async def ai_generate(self, prompt: str, max_tokens: int = 150) -> Optional[str]:
        """SkuteÄnÃ© AI generovÃ¡nÃ­ s thermal protection"""
        
        # Pre-generation safety check
        if not self.thermal_safety_check():
            return None
            
        print(f"ğŸ¤– Generating with {self.model_name}...")
        
        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "options": {
                "num_predict": max_tokens,
                "temperature": 0.3,  # NiÅ¾Å¡Ã­ temperatura = rychlejÅ¡Ã­
                "top_p": 0.9,
                "num_ctx": 1024,     # MenÅ¡Ã­ context = rychlejÅ¡Ã­
            },
            "stream": False
        }
        
        try:
            async with aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=30)
            ) as session:
                
                # Monitor temperature during request
                start_temp = self.get_cpu_temperature()
                
                async with session.post(
                    f"{self.ollama_url}/api/generate", 
                    json=payload
                ) as response:
                    
                    if response.status == 200:
                        result = await response.json()
                        
                        # Post-generation safety check
                        end_temp = self.get_cpu_temperature()
                        if end_temp and start_temp:
                            temp_rise = end_temp - start_temp
                            print(f"ğŸŒ¡ï¸ Temperature rise: +{temp_rise}Â°C")
                            
                            if temp_rise > 5:  # Pokud vzrostla o vÃ­ce neÅ¾ 5Â°C
                                print("âš ï¸ Significant temperature rise - cooling down")
                                time.sleep(10)
                        
                        return result.get('response', '').strip()
                    else:
                        print(f"âŒ AI request failed: {response.status}")
                        return None
                        
        except asyncio.TimeoutError:
            print("â° AI generation timeout")
            return None
        except Exception as e:
            print(f"âŒ AI generation error: {e}")
            return None
    
    async def interactive_mycoder(self):
        """InteraktivnÃ­ MyCoder session"""
        print("ğŸš€ Real MyCoder - Interactive AI Coding Assistant")
        print("=" * 55)
        print("ğŸŒ¡ï¸ Thermal-protected real AI generation active")
        print("ğŸ’¡ Type 'quit' to exit, 'temp' for temperature")
        print("=" * 55)
        
        session_count = 0
        
        while True:
            try:
                # Pre-prompt thermal check
                if not self.thermal_safety_check():
                    print("ğŸš¨ System too hot! Exiting for safety.")
                    break
                
                # Get user input
                print(f"\n[Session {session_count + 1}]")
                user_input = input("ğŸ”¥ MyCoder> ").strip()
                
                if user_input.lower() == 'quit':
                    print("ğŸ‘‹ Goodbye!")
                    break
                    
                if user_input.lower() == 'temp':
                    temp = self.get_cpu_temperature()
                    print(f"ğŸŒ¡ï¸ Current temperature: {temp}Â°C")
                    continue
                
                if not user_input:
                    continue
                
                # Create coding-focused prompt
                coding_prompt = f"Write a Python function or code snippet for: {user_input}\n\nProvide clean, working code with brief explanation:"
                
                # Generate AI response
                response = await self.ai_generate(coding_prompt, max_tokens=200)
                
                if response:
                    print("\nğŸ¤– MyCoder AI Response:")
                    print("-" * 40)
                    print(response)
                    print("-" * 40)
                else:
                    print("âŒ AI generation failed or thermal protection activated")
                
                session_count += 1
                
                # Inter-session cooldown
                if session_count % 3 == 0:  # KaÅ¾dÃ© 3 requesty
                    print("ğŸ’¤ Session cooldown (10s)...")
                    time.sleep(10)
                
            except KeyboardInterrupt:
                print("\nğŸ›‘ Session interrupted")
                break
            except Exception as e:
                print(f"âŒ Session error: {e}")
                self.emergency_thermal_stop()
                break
        
        # Final status
        final_temp = self.get_cpu_temperature()
        print(f"\nğŸ“Š Session completed. Final temperature: {final_temp}Â°C")

async def main():
    """Main MyCoder launcher"""
    print("ğŸ”¥ Real MyCoder with AI Generation")
    print("âš ï¸  Ultra-Safe Thermal Protection Active")
    
    # Check if Ollama is running
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get("http://localhost:11434/api/tags") as response:
                if response.status != 200:
                    print("âŒ Ollama server not accessible")
                    return
    except:
        print("âŒ Ollama server not running. Please start with 'ollama serve'")
        return
    
    # Initialize and run MyCoder
    mycoder = ThermalMyCoder()
    await mycoder.interactive_mycoder()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except Exception as e:
        print(f"ğŸ’¥ MyCoder crashed: {e}")
        # Emergency cleanup
        subprocess.run(["pkill", "-f", "python.*mycoder"], check=False)