#!/usr/bin/env python3

"""
Final MyCoder Test - With Smart Thermal Management
"""

import time
import subprocess
import sys
import os

def get_temp():
    try:
        result = subprocess.run(["sensors"], capture_output=True, text=True, timeout=3)
        for line in result.stdout.split('\n'):
            if "Core 0:" in line and "+" in line:
                temp_str = line.split('+')[1].split('Â°')[0]
                return int(float(temp_str))
    except:
        pass
    return 0

def thermal_check(operation_name):
    temp = get_temp()
    print(f"ğŸŒ¡ï¸ {operation_name}: {temp}Â°C", end="")
    
    if temp > 75:
        print(" ğŸš¨ TOO HOT! Aborting")
        return False
    elif temp > 70:
        print(" âš ï¸ Warning - cooling 10s")
        time.sleep(10)
        return thermal_check(operation_name)
    else:
        print(" âœ… Safe")
        return True

def simple_ai_request():
    if not thermal_check("Pre-AI"):
        return None
        
    print("ğŸ¤– Requesting simple AI generation...")
    
    # Ultra-simple request with timeout
    payload = {
        "model": "tinyllama:1.1b",
        "prompt": "def hello():",
        "options": {"num_predict": 30}
    }
    
    import json
    cmd = [
        "curl", "-s", "-X", "POST", 
        "http://localhost:11434/api/generate",
        "-H", "Content-Type: application/json",
        "-d", json.dumps(payload),
        "--max-time", "45"
    ]
    
    try:
        start_temp = get_temp()
        start_time = time.time()
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
        
        end_time = time.time()
        end_temp = get_temp()
        
        duration = end_time - start_time
        temp_rise = end_temp - start_temp
        
        print(f"â±ï¸ Duration: {duration:.1f}s | Temperature: {start_temp}Â°C â†’ {end_temp}Â°C ({temp_rise:+d}Â°C)")
        
        if result.returncode == 0:
            try:
                response_data = json.loads(result.stdout)
                response = response_data.get('response', '').strip()
                if response:
                    print("ğŸ¤– AI Response:")
                    print(f"   {response}")
                    return response
                else:
                    print("âŒ Empty response")
            except json.JSONDecodeError:
                print("âŒ JSON decode error")
        else:
            print(f"âŒ Request failed: {result.returncode}")
            
    except subprocess.TimeoutExpired:
        print("â° AI request timeout (60s)")
    except Exception as e:
        print(f"âŒ AI request error: {e}")
    
    thermal_check("Post-AI")
    return None

def main():
    print("ğŸ”¥ Final MyCoder Test - Smart Thermal Protection")
    print("=" * 50)
    
    # Initial status
    if not thermal_check("Initial"):
        print("ğŸš¨ System too hot to start!")
        return
        
    # Test Ollama connectivity
    try:
        result = subprocess.run(
            ["curl", "-s", "http://localhost:11434/api/tags"],
            capture_output=True, timeout=5
        )
        if result.returncode != 0:
            print("âŒ Ollama not running")
            return
        print("âœ… Ollama connected")
    except:
        print("âŒ Ollama connection failed")
        return
    
    # Simple AI generation test
    print("\nğŸ“ Testing AI Code Generation...")
    response = simple_ai_request()
    
    if response:
        print("\nğŸ‰ SUCCESS! MyCoder AI generation works with thermal protection!")
    else:
        print("\nâš ï¸ AI generation failed or was thermally protected")
    
    # Final thermal check
    final_temp = get_temp()
    print(f"\nğŸ“Š Final temperature: {final_temp}Â°C")
    
    if final_temp < 60:
        print("âœ… System remained cool - safe for continued use")
    elif final_temp < 70:
        print("âš–ï¸ System warm but stable - monitor for longer sessions")
    else:
        print("ğŸ”¥ System hot - needs cooling before next session")

if __name__ == "__main__":
    main()